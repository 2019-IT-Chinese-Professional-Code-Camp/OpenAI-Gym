{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "frozenlake.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-FH_e2iWEiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B388nLZ_y6TE",
        "colab_type": "text"
      },
      "source": [
        "# Frozen Lake environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08TwEWjIwxxz",
        "colab_type": "text"
      },
      "source": [
        "*Winter is here. You and your friends were tossing around a frisbee at the park when you made a wild throw that left the frisbee out in the middle of the lake. The water is mostly frozen, but there are a few holes where the ice has melted. If you step into one of those holes, you'll fall into the freezing water. At this time, there's an international frisbee shortage, so it's absolutely imperative that you navigate across the lake and retrieve the disc. However, the ice is slippery, so you won't always move in the direction you intend.*\n",
        "\n",
        "The surface is described using a grid like the following:\n",
        "\n",
        "**SFFF**       (S: starting point, safe)\n",
        "\n",
        "**FHFH**       (F: frozen surface, safe)\n",
        "\n",
        "**FFFH**      (H: hole, fall to your doom)\n",
        "\n",
        "**HFFG**       (G: goal, where the frisbee is located)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mXmLlLCwzLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgTQGu9wWTK6",
        "colab_type": "code",
        "outputId": "bea9c56a-867e-4e23-91f5-510f7556b428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "env = gym.make(\"FrozenLake-v0\")\n",
        "\n",
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "print(state_space_size,action_space_size)\n",
        "print(q_table)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16 4\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsKDXtX0EOYY",
        "colab_type": "text"
      },
      "source": [
        "**Without training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkeOqwtpXLbK",
        "colab_type": "code",
        "outputId": "4abaa6b2-71eb-4a09-a2a5-8feb67d1be54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "for episode in range(3):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    print(\"*****EPISODE \", episode+1, \"*****\\n\\n\\n\\n\")\n",
        "    time.sleep(1)\n",
        "    for step in range(100):        \n",
        "        clear_output(wait=True)\n",
        "        env.render()\n",
        "        time.sleep(0.3)\n",
        "        \n",
        "        action = env.action_space.sample()        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        if done:\n",
        "            clear_output(wait=True)\n",
        "            env.render()\n",
        "            if reward == 1:\n",
        "                print(\"****You reached the goal!****\")\n",
        "                time.sleep(3)\n",
        "            else:\n",
        "                print(\"****You fell through a hole!****\")\n",
        "                time.sleep(3)\n",
        "                clear_output(wait=True)\n",
        "            break\n",
        "        state = new_state"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (Up)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "****You fell through a hole!****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un-s5TxNFHRs",
        "colab_type": "text"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgNpObB5q2TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize new episode params\n",
        "num_episodes = 10000\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "exploration_rate = 1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.001\n",
        "\n",
        "rewards_all_episodes = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTRndAlXrE6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    rewards_current_episode = 0\n",
        "    for step in range(max_steps_per_episode): \n",
        "\n",
        "        # Exploration-exploitation trade-off\n",
        "        exploration_rate_threshold = random.uniform(0, 1)\n",
        "        if exploration_rate_threshold > exploration_rate:\n",
        "            action = np.argmax(q_table[state,:]) \n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "    \n",
        "        # Update Q-table for Q(s,a)\n",
        "        q_table[state, action] = q_table[state, action] * (1 - learning_rate) + \\\n",
        "        learning_rate * (reward + discount_rate * np.max(q_table[new_state, :]))\n",
        "    \n",
        "        state = new_state\n",
        "        rewards_current_episode += reward \n",
        "        \n",
        "        if done == True: \n",
        "            break\n",
        "    # Exploration rate decay\n",
        "    exploration_rate = min_exploration_rate + \\\n",
        "    (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n",
        "    \n",
        "    rewards_all_episodes.append(rewards_current_episode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsfHq7fQrXpS",
        "colab_type": "code",
        "outputId": "5fcc97b5-f032-4b54-a92a-ab6a48e2351c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "rewards_per_thosand_episodes = np.split(np.array(rewards_all_episodes),num_episodes/1000)\n",
        "count = 1000\n",
        "\n",
        "print(\"********Average reward per thousand episodes********\\n\")\n",
        "for r in rewards_per_thosand_episodes:\n",
        "    print(count, \": \", str(sum(r/1000)))\n",
        "    count += 1000\n",
        "#check learned q_table    \n",
        "print (q_table)    "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********Average reward per thousand episodes********\n",
            "\n",
            "1000 :  0.04100000000000003\n",
            "2000 :  0.21400000000000016\n",
            "3000 :  0.3870000000000003\n",
            "4000 :  0.5940000000000004\n",
            "5000 :  0.6600000000000005\n",
            "6000 :  0.6790000000000005\n",
            "7000 :  0.6970000000000005\n",
            "8000 :  0.6480000000000005\n",
            "9000 :  0.6820000000000005\n",
            "10000 :  0.7070000000000005\n",
            "[[0.60516995 0.5386453  0.52408858 0.51957365]\n",
            " [0.36906431 0.42897573 0.28802314 0.54637556]\n",
            " [0.42749444 0.4300228  0.42792291 0.49349829]\n",
            " [0.22872645 0.27780515 0.31199003 0.4568145 ]\n",
            " [0.62821896 0.34605081 0.40819195 0.37774986]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.15883225 0.11373592 0.48072785 0.15307569]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.46820115 0.4226666  0.44646938 0.68243833]\n",
            " [0.42833862 0.76187934 0.50419697 0.37672503]\n",
            " [0.7694025  0.38931128 0.42103453 0.33145846]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.39430926 0.60968332 0.81070886 0.39377397]\n",
            " [0.75984402 0.88455931 0.81162811 0.77913293]\n",
            " [0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO9tI5_GFkGb",
        "colab_type": "text"
      },
      "source": [
        "**Play**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM3-q-Kirb_L",
        "colab_type": "code",
        "outputId": "272678fe-0577-4a71-8576-a6d65ba69f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "for episode in range(3):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    print(\"*****EPISODE \", episode+1, \"*****\\n\\n\\n\\n\")\n",
        "    time.sleep(1)\n",
        "    for step in range(max_steps_per_episode):        \n",
        "        clear_output(wait=True)\n",
        "        env.render()\n",
        "        time.sleep(0.3)\n",
        "        \n",
        "        action = np.argmax(q_table[state,:])        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        if done:\n",
        "            clear_output(wait=True)\n",
        "            env.render()\n",
        "            if reward == 1:\n",
        "                print(\"****You reached the goal!****\")\n",
        "                time.sleep(3)\n",
        "            else:\n",
        "                print(\"****You fell through a hole!****\")\n",
        "                time.sleep(3)\n",
        "                clear_output(wait=True)\n",
        "            break\n",
        "        state = new_state"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "****You reached the goal!****\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}